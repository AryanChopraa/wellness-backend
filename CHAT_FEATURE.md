# Chat feature — AI, history, rate limit

This document describes the in-app chat feature: AI provider, conversation history, and the **per-conversation message rate limit**.

---

## Overview

- **Multiple conversations per user** — Each user can create and list their own conversations.
- **Messages per conversation** — Each conversation has a ordered list of messages (user and assistant).
- **AI** — Assistant replies are generated by **Venice AI** (chat completions API). A fixed system prompt is used; full conversation history is sent so the model keeps context.
- **Persistence** — Every user message and every assistant reply is stored in the database.
- **Titles** — Each conversation has a **title**. New conversations start as "New conversation"; after the **first** user message and first AI reply, the backend uses the same AI (Venice) to generate a short title from that first exchange and updates the conversation. So the title is AI-generated from the first message pair.
- **Rate limit** — Each conversation is limited to **100 messages total** (user + assistant combined). When the limit is reached, the backend **does not call the AI** and **does not save** the new user message; it returns a 429 response with a clear “rate limit reached” payload.

---

## AI (Venice)

- **Provider:** Venice AI (`https://api.venice.ai/api/v1/chat/completions`).
- **Model:** Configurable via `VENICE_CHAT_MODEL` (default: `venice-uncensored`). API key via `VENICE_API_KEY`.
- **System prompt:** A fixed wellness-assistant system prompt is sent with every request (helpful, friendly, health/wellness/fitness/nutrition focus; suggests consulting a professional when appropriate).
- **Request shape:** Each request sends:
  1. One system message (the fixed prompt).
  2. All previous messages in the conversation in order (user / assistant), plus the new user message.
- **Response:** The API returns the assistant’s text; that text is stored as a new `assistant` message and returned to the client.

---

## Conversation title (AI-generated)

- **When:** After the **first** user message and first assistant reply in a conversation, the backend calls Venice again with a dedicated prompt: “Generate a short title (2–8 words) based on the first user message and first assistant response.”
- **Storage:** The returned title is saved on the `Conversation` document and returned in the list and in the history response.
- **Fallback:** If title generation fails or returns empty, the conversation keeps the default title ("New conversation"). The chat response still succeeds.
- **Response:** On the first message in a conversation, the **POST /chat/conversations/:id/messages** success response may include `conversationTitle` with the new title so the frontend can update the UI without refetching.

---

## Conversation history

- **Endpoint:** **GET /chat/conversations/:id** returns the conversation (including its AI-generated title) and **all messages** in order. Use this to load chat history for a given conversation.
- **Storage:** `Conversation` (per user, with `title`) and `Message` (per conversation, with `role`: `user` | `assistant` and `content`).
- **Order:** Messages are always read and sent to the AI in `createdAt` ascending order so the model sees the correct thread.
- **Sending to AI:** For each new user message, the backend loads all existing messages for that conversation, appends the new user message, and sends the full list (with the system prompt) to Venice. So the AI always has full history for that conversation.

---

## Rate limit (100 messages per conversation)

- **Limit:** **100 messages total** per conversation (count of both user and assistant messages).
- **When it applies:** On **POST /chat/conversations/:id/messages** (send message).
- **Check:** Before calling the AI or writing anything to the DB, the backend counts messages for that conversation. If adding one user message and one assistant message would exceed 100 (i.e. `currentCount + 2 > 100`), the request is **rejected**.
- **What happens when the limit is reached:**
  - The backend **does not** call the Venice API (no AI response).
  - The backend **does not** save the user’s message to the database.
  - The backend returns **HTTP 429** with a JSON body that includes:
    - `error`: `"Rate limit reached"`
    - `message`: `"Rate limit reached"`
    - `rateLimitReached`: `true`
    - `content`: A short user-facing sentence (e.g. “Rate limit reached. This conversation has reached the maximum number of messages.”)
- **Frontend:** On 429 and/or `rateLimitReached === true`, the UI should show the `content` (or `message`) and not treat the last user input as a successful message (nothing was stored).

**Example — at limit:**

- Conversation already has 99 messages. User sends another message.
- Backend: `currentCount = 99`, `99 + 2 > 100` → rate limit. Return 429, no AI call, no DB write.
- Conversation still has 99 messages; the new user message is not stored.

**Example — one below limit:**

- Conversation has 98 messages. User sends a message.
- Backend: allows (98 + 2 = 100). User message and assistant reply are both stored. Conversation then has 100 messages. Next send will hit the limit.

---

## API summary (chat)

| Method | Path | Auth | Description |
|--------|------|------|-------------|
| POST | `/chat/conversations` | Bearer | Create conversation (body: `{ title?: string }`). |
| GET | `/chat/conversations` | Bearer | List current user’s conversations. |
| GET | `/chat/conversations/:id` | Bearer | Get one conversation (with AI-generated title) and all its messages (full history). |
| POST | `/chat/conversations/:id/messages` | Bearer | Send message (body: `{ content: string }`). Returns user + assistant messages when under limit; **429 + rateLimitReached** when at/over 100 messages, **no AI response**. |

---

## Response shapes

**Success (201) — message sent and AI replied:**

- `userMessage`: `{ id, role: "user", content, createdAt }`
- `assistantMessage`: `{ id, role: "assistant", content, createdAt }`
- `rateLimitReached`: `false`
- `conversationTitle`: (optional) Present only on the **first** message in a conversation; the AI-generated title so the client can update the conversation list without refetching.

**Rate limit (429) — no AI call, no new messages stored:**

- `success`: `false` (from global wrapper)
- `message`: `"Rate limit reached"`
- `error`: `"Rate limit reached"`
- `rateLimitReached`: `true`
- `content`: User-facing sentence explaining the limit.

Use `rateLimitReached` and HTTP 429 so the frontend can show the right UI and not add the “last” user message to the thread as if it were sent.

**Success (200) — GET /chat/conversations/:id (history):**

- `conversation`: `{ id, title, createdAt, updatedAt, messageCount }` (title is AI-generated after first exchange)
- `messages`: array of `{ id, role, content, createdAt }` in chronological order
